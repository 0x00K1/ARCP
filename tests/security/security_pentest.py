#!/usr/bin/env python3
"""
ARCP Security Penetration Testing Suite

This script performs comprehensive security testing including:
1. Authentication bypass attempts
2. Token manipulation attacks
3. Rate limiting bypass attempts
4. Session hijacking tests
5. Input validation attacks
6. Authorization escalation attempts
7. Timing attacks
8. SQL injection attempts
9. Cross-site scripting (XSS) tests
10. CSRF attacks

Usage:
    python security_pentest.py --target http://localhost:8001 --verbose
"""

import argparse
import asyncio
import base64
import json
import sys
import time
from datetime import datetime
from typing import Dict, List

import httpx
import jwt


class SecurityTester:
    """Comprehensive security testing for ARCP authentication system."""

    def __init__(self, base_url: str = "http://localhost:8001", verbose: bool = False):
        self.base_url = base_url
        self.verbose = verbose
        self.vulnerabilities = []
        self.test_results = []

        # Test credentials and keys
        self.valid_agent_key = "test_agent_key_001_secure_development"
        self.invalid_keys = [
            "invalid_key_123",
            "test_agent_key_001_secure_development_modified",
            "",
            " ",
            "null",
            "undefined",
            "admin",
            "password",
            "123456",
        ]

        # Admin credentials for testing
        self.admin_username = "admin"
        self.admin_password = "admin123"  # Default from config

    def log(self, message: str, level: str = "INFO"):
        """Log a message with timestamp."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        prefix = level
        if self.verbose or level != "INFO":
            print(f"[{timestamp}] {prefix} {message}")

    def add_vulnerability(
        self,
        title: str,
        description: str,
        severity: str = "MEDIUM",
        details: Dict = None,
    ):
        """Add a discovered vulnerability."""
        vuln = {
            "title": title,
            "description": description,
            "severity": severity,
            "timestamp": datetime.now().isoformat(),
            "details": details or {},
        }
        self.vulnerabilities.append(vuln)
        self.log(f"VULNERABILITY [{severity}]: {title}", "ERROR")

    def add_test_result(self, test_name: str, success: bool, details: str = ""):
        """Add a test result."""
        result = {
            "test": test_name,
            "success": success,
            "details": details,
            "timestamp": datetime.now().isoformat(),
        }
        self.test_results.append(result)
        status = "PASS" if success else "FAIL"
        self.log(f"TEST [{status}]: {test_name} - {details}")

    async def test_authentication_bypass(self) -> List[Dict]:
        """Test 1: Authentication bypass attempts."""
        self.log("Testing Authentication Bypass Attacks...")

        bypass_attempts = []

        async with httpx.AsyncClient() as session:
            # Test 1.1: SQL Injection in login
            sql_payloads = [
                "' OR '1'='1' --",
                "admin'; DROP TABLE users; --",
                "' UNION SELECT * FROM users --",
                "admin'/**/OR/**/1=1#",
                "' OR 1=1 LIMIT 1 --",
            ]

            for payload in sql_payloads:
                try:
                    data = {"username": payload, "password": "any_password"}
                    response = await session.post(
                        f"{self.base_url}/auth/login", json=data
                    )
                    try:
                        result = await response.json()
                    except Exception:
                        result = {}
                    if response.status_code == 200 and "access_token" in result:
                        self.add_vulnerability(
                            "SQL Injection in Login",
                            f"SQL injection payload '{payload}' bypassed authentication",
                            "CRITICAL",
                            {"payload": payload, "response": result},
                        )
                        bypass_attempts.append(
                            {
                                "method": "SQL Injection",
                                "payload": payload,
                                "success": True,
                            }
                        )
                    else:
                        bypass_attempts.append(
                            {
                                "method": "SQL Injection",
                                "payload": payload,
                                "success": False,
                            }
                        )
                except Exception as e:
                    self.log(f"SQL injection test failed: {e}", "WARN")

            # Test 1.2: NoSQL Injection
            nosql_payloads = [
                {"$ne": None},
                {"$regex": ".*"},
                {"$where": "1==1"},
            ]

            for payload in nosql_payloads:
                try:
                    data = {"username": payload, "password": payload}
                    response = await session.post(
                        f"{self.base_url}/auth/login", json=data
                    )
                    result = await response.json()
                    if response.status_code == 200 and "access_token" in result:
                        self.add_vulnerability(
                            "NoSQL Injection in Login",
                            "NoSQL injection bypassed authentication",
                            "CRITICAL",
                            {"payload": str(payload), "response": result},
                        )
                except Exception:
                    pass  # Expected to fail

            # Test 1.3: JSON Structure Manipulation
            json_attacks = [
                {"username": "admin", "password": "wrong", "role": "admin"},
                {"username": "admin", "password": {"$ne": ""}},
                {"username": ["admin"], "password": "wrong"},
                {
                    "username": "admin",
                    "password": "wrong",
                    "authenticated": True,
                },
            ]

            for attack in json_attacks:
                try:
                    response = await session.post(
                        f"{self.base_url}/auth/login", json=attack
                    )
                    result = await response.json()
                    if response.status_code == 200 and "access_token" in result:
                        self.add_vulnerability(
                            "JSON Structure Manipulation",
                            "Authentication bypassed through JSON manipulation",
                            "HIGH",
                            {"payload": attack, "response": result},
                        )
                except Exception:
                    pass

        self.add_test_result(
            "Authentication Bypass Tests",
            len(bypass_attempts) > 0,
            f"Tested {len(sql_payloads) + len(nosql_payloads) + len(json_attacks)} attack vectors",
        )
        return bypass_attempts

    async def test_token_manipulation(self) -> List[Dict]:
        """Test 2: JWT Token manipulation attacks."""
        self.log("Testing Token Manipulation Attacks...")

        token_attacks = []

        # First, get a valid token
        async with httpx.AsyncClient() as session:
            # Get valid agent temp token
            temp_token = None
            try:
                data = {
                    "agent_id": "test_pentest_001",
                    "agent_type": "pentest",
                    "agent_key": self.valid_agent_key,
                }
                response = await session.post(
                    f"{self.base_url}/auth/agent/request_temp_token", json=data
                )
                if response.status_code == 200:
                    result = await response.json()
                    temp_token = result["temp_token"]
            except Exception as e:
                self.log(f"Could not obtain temp token: {e}", "WARN")

            if temp_token:
                # Test 2.1: Token Algorithm Confusion
                try:
                    # Decode token without verification to see structure
                    decoded = jwt.decode(
                        temp_token, options={"verify_signature": False}
                    )

                    # Test algorithm confusion attacks
                    algorithms_to_test = ["none", "HS512", "RS256", "ES256"]

                    for alg in algorithms_to_test:
                        # Create malicious token with different algorithm
                        malicious_payload = decoded.copy()
                        malicious_payload["role"] = "admin"  # Escalate privileges
                        malicious_payload["exp"] = (
                            int(time.time()) + 3600
                        )  # Extend expiration

                        try:
                            if alg == "none":
                                # None algorithm attack
                                header = (
                                    base64.urlsafe_b64encode(
                                        json.dumps(
                                            {"alg": "none", "typ": "JWT"}
                                        ).encode()
                                    )
                                    .decode()
                                    .rstrip("=")
                                )
                                payload = (
                                    base64.urlsafe_b64encode(
                                        json.dumps(malicious_payload).encode()
                                    )
                                    .decode()
                                    .rstrip("=")
                                )
                                malicious_token = f"{header}.{payload}."
                            else:
                                # Try to sign with weak key
                                malicious_token = jwt.encode(
                                    malicious_payload, "secret", algorithm=alg
                                )

                            # Test if malicious token is accepted
                            headers = {"Authorization": f"Bearer {malicious_token}"}
                            test_response = await session.get(
                                f"{self.base_url}/auth/session_status",
                                headers=headers,
                            )
                            if test_response.status_code == 200:
                                self.add_vulnerability(
                                    f"JWT Algorithm Confusion - {alg}",
                                    f"Token with algorithm {alg} was accepted, potentially allowing privilege escalation",
                                    "CRITICAL",
                                    {
                                        "algorithm": alg,
                                        "original_token": temp_token[:20] + "...",
                                        "malicious_token": malicious_token[:20] + "...",
                                    },
                                )
                                token_attacks.append(
                                    {
                                        "method": f"Algorithm Confusion ({alg})",
                                        "success": True,
                                    }
                                )
                            else:
                                token_attacks.append(
                                    {
                                        "method": f"Algorithm Confusion ({alg})",
                                        "success": False,
                                    }
                                )

                        except Exception as e:
                            self.log(
                                f"Algorithm confusion test for {alg} failed: {e}",
                                "WARN",
                            )

                except Exception as e:
                    self.log(f"Token manipulation setup failed: {e}", "WARN")

                # Test 2.2: Token Tampering
                try:
                    # Test various token tampering techniques
                    tampering_tests = [
                        (
                            "Modified payload",
                            temp_token[:-10] + "modified",
                        ),  # Modify end of token
                        (
                            "Extra characters",
                            temp_token + "extra",
                        ),  # Add extra characters
                        (
                            "Truncated token",
                            temp_token[:-20],
                        ),  # Truncate token
                        (
                            "Case modification",
                            temp_token.upper(),
                        ),  # Change case
                        (
                            "Special characters",
                            temp_token.replace("a", "@"),
                        ),  # Replace characters
                    ]

                    for test_name, tampered_token in tampering_tests:
                        try:
                            headers = {"Authorization": f"Bearer {tampered_token}"}
                            test_response = await session.get(
                                f"{self.base_url}/auth/session_status",
                                headers=headers,
                            )
                            if test_response.status_code == 200:
                                self.add_vulnerability(
                                    f"Token Tampering - {test_name}",
                                    f"Tampered token was accepted: {test_name}",
                                    "HIGH",
                                    {
                                        "tampering_method": test_name,
                                        "original": temp_token[:20] + "...",
                                        "tampered": tampered_token[:20] + "...",
                                    },
                                )
                                token_attacks.append(
                                    {
                                        "method": f"Tampering ({test_name})",
                                        "success": True,
                                    }
                                )
                            else:
                                token_attacks.append(
                                    {
                                        "method": f"Tampering ({test_name})",
                                        "success": False,
                                    }
                                )
                        except Exception:
                            token_attacks.append(
                                {
                                    "method": f"Tampering ({test_name})",
                                    "success": False,
                                }
                            )

                except Exception as e:
                    self.log(f"Token tampering tests failed: {e}", "WARN")

        self.add_test_result(
            "Token Manipulation Tests",
            len([a for a in token_attacks if a["success"]]) == 0,
            "Tested token manipulation techniques",
        )
        return token_attacks

    async def test_rate_limiting_bypass(self) -> List[Dict]:
        """Test 3: Rate limiting bypass attempts."""
        self.log("Testing Rate Limiting Bypass...")

        bypass_attempts = []

        async with httpx.AsyncClient() as session:
            # Test 3.1: IP Header Manipulation
            ip_headers = [
                {"X-Forwarded-For": "192.168.1.100"},
                {"X-Real-IP": "10.0.0.50"},
                {"X-Client-IP": "172.16.0.200"},
                {"X-Originating-IP": "203.0.113.1"},
                {"X-Remote-Addr": "198.51.100.1"},
                {"CF-Connecting-IP": "8.8.8.8"},  # Cloudflare
            ]

            for headers in ip_headers:
                failed_attempts = 0
                for attempt in range(10):  # Try to exceed rate limit
                    try:
                        data = {
                            "username": "admin",
                            "password": f"wrong_password_{attempt}",
                        }
                        response = await session.post(
                            f"{self.base_url}/auth/login",
                            json=data,
                            headers=headers,
                        )
                        if response.status_code == 429:  # Rate limited
                            break
                        elif response.status_code == 401:  # Failed login (expected)
                            failed_attempts += 1
                        else:
                            # Unexpected response
                            result = await response.json()
                            self.log(
                                f"Unexpected response during rate limit test: {response.status_code} - {result}"
                            )
                    except Exception as e:
                        self.log(f"Rate limit bypass test error: {e}", "WARN")
                        break

                if (
                    failed_attempts >= 8
                ):  # If we made more attempts than the rate limit should allow
                    self.add_vulnerability(
                        "Rate Limiting Bypass via IP Headers",
                        f"Rate limiting bypassed using header: {list(headers.keys())[0]}",
                        "MEDIUM",
                        {
                            "bypassed_header": headers,
                            "successful_attempts": failed_attempts,
                        },
                    )
                    bypass_attempts.append(
                        {
                            "method": f"IP Header ({list(headers.keys())[0]})",
                            "success": True,
                        }
                    )
                else:
                    bypass_attempts.append(
                        {
                            "method": f"IP Header ({list(headers.keys())[0]})",
                            "success": False,
                        }
                    )

            # Test 3.2: User-Agent Rotation
            user_agents = [
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36",
                "curl/7.68.0",
                "PostmanRuntime/7.28.0",
                "python-requests/2.25.1",
            ]

            failed_attempts = 0
            for i, ua in enumerate(
                user_agents * 3
            ):  # Multiple rounds with different UAs
                try:
                    headers = {"User-Agent": ua}
                    data = {
                        "username": "admin",
                        "password": f"wrong_password_{i}",
                    }
                    response = await session.post(
                        f"{self.base_url}/auth/login",
                        json=data,
                        headers=headers,
                    )
                    if response.status_code == 429:
                        break
                    elif response.status_code == 401:
                        failed_attempts += 1
                except Exception:
                    break

            if failed_attempts >= 10:
                self.add_vulnerability(
                    "Rate Limiting Bypass via User-Agent Rotation",
                    "Rate limiting bypassed by rotating User-Agent headers",
                    "MEDIUM",
                    {"successful_attempts": failed_attempts},
                )
                bypass_attempts.append(
                    {"method": "User-Agent Rotation", "success": True}
                )
            else:
                bypass_attempts.append(
                    {"method": "User-Agent Rotation", "success": False}
                )

            # Test 3.3: Distributed Requests (Session-based bypass)
            sessions = [httpx.AsyncClient() for _ in range(5)]
            try:
                failed_attempts = 0
                for session_obj in sessions:
                    for attempt in range(3):
                        try:
                            data = {
                                "username": "admin",
                                "password": f"wrong_password_session_{attempt}",
                            }
                            response = await session_obj.post(
                                f"{self.base_url}/auth/login", json=data
                            )
                            if response.status_code == 401:
                                failed_attempts += 1
                            elif response.status_code == 429:
                                break
                        except Exception:
                            break

                if failed_attempts >= 8:
                    self.add_vulnerability(
                        "Rate Limiting Bypass via Multiple Sessions",
                        "Rate limiting bypassed using multiple HTTP sessions",
                        "MEDIUM",
                        {"successful_attempts": failed_attempts},
                    )
                    bypass_attempts.append(
                        {"method": "Multiple Sessions", "success": True}
                    )
                else:
                    bypass_attempts.append(
                        {"method": "Multiple Sessions", "success": False}
                    )

            finally:
                for session_obj in sessions:
                    await session_obj.aclose()

        self.add_test_result(
            "Rate Limiting Bypass Tests",
            len([a for a in bypass_attempts if a["success"]]) == 0,
            "Tested rate limiting bypass techniques",
        )
        return bypass_attempts

    async def test_session_hijacking(self) -> List[Dict]:
        """Test 4: Session hijacking and fixation attacks."""
        self.log("Testing Session Security...")

        session_attacks = []

        async with httpx.AsyncClient() as session:
            # Test 4.1: Session Token Prediction
            tokens = []
            for i in range(5):
                try:
                    data = {
                        "agent_id": f"test_session_{i}",
                        "agent_type": "testing",
                        "agent_key": self.valid_agent_key,
                    }
                    response = await session.post(
                        f"{self.base_url}/auth/agent/request_temp_token",
                        json=data,
                    )
                    if response.status_code == 200:
                        result = await response.json()
                        tokens.append(result["temp_token"])

                        # Wait a bit to see if tokens are time-based
                        await asyncio.sleep(0.1)
                except Exception as e:
                    self.log(f"Token generation test failed: {e}", "WARN")

            # Analyze token patterns
            if len(tokens) >= 3:
                # Check if tokens have predictable patterns
                token_similarities = []
                for i in range(len(tokens) - 1):
                    # Compare consecutive tokens
                    t1_parts = tokens[i].split(".")
                    t2_parts = tokens[i + 1].split(".")

                    if len(t1_parts) >= 2 and len(t2_parts) >= 2:
                        # Compare headers and payloads
                        header_similarity = t1_parts[0] == t2_parts[0]
                        payload_similar = (
                            len(set(t1_parts[1]).intersection(set(t2_parts[1])))
                            / max(len(t1_parts[1]), len(t2_parts[1]))
                            > 0.8
                        )

                        token_similarities.append(
                            {
                                "header_identical": header_similarity,
                                "payload_similar": payload_similar,
                            }
                        )

                if any(
                    s["header_identical"] and s["payload_similar"]
                    for s in token_similarities
                ):
                    self.add_vulnerability(
                        "Predictable Token Generation",
                        "Generated tokens show predictable patterns that could enable session prediction",
                        "MEDIUM",
                        {
                            "token_count": len(tokens),
                            "similarities": token_similarities,
                        },
                    )
                    session_attacks.append(
                        {"method": "Token Prediction", "success": True}
                    )
                else:
                    session_attacks.append(
                        {"method": "Token Prediction", "success": False}
                    )

            # Test 4.2: Session Fixation
            # Try to set a specific session identifier and see if it's accepted
            try:
                fixed_session_id = "FIXED_SESSION_123456789"
                headers = {
                    "Cookie": f"session_id={fixed_session_id}",
                    "X-Session-ID": fixed_session_id,
                }

                data = {
                    "username": self.admin_username,
                    "password": self.admin_password,
                }
                response = await session.post(
                    f"{self.base_url}/auth/login", json=data, headers=headers
                )
                if response.status_code == 200:
                    result = await response.json()

                    # Check if the fixed session ID is reflected in response or cookies
                    response_cookies = response.headers.get("Set-Cookie", "")
                    if fixed_session_id in response_cookies or fixed_session_id in str(
                        result
                    ):
                        self.add_vulnerability(
                            "Session Fixation",
                            "Application accepts client-provided session identifiers",
                            "HIGH",
                            {
                                "fixed_session_id": fixed_session_id,
                                "response_cookies": response_cookies,
                            },
                        )
                        session_attacks.append(
                            {"method": "Session Fixation", "success": True}
                        )
                    else:
                        session_attacks.append(
                            {"method": "Session Fixation", "success": False}
                        )
            except Exception:
                session_attacks.append({"method": "Session Fixation", "success": False})

        self.add_test_result(
            "Session Security Tests",
            len([a for a in session_attacks if a["success"]]) == 0,
            "Tested session security mechanisms",
        )
        return session_attacks

    async def test_input_validation(self) -> List[Dict]:
        """Test 5: Input validation and injection attacks."""
        self.log("Testing Input Validation...")

        validation_attacks = []

        async with httpx.AsyncClient() as session:
            # Test 5.1: Oversized Input Attacks
            oversized_payloads = [
                ("username", "A" * 10000),  # Very long username
                ("password", "B" * 50000),  # Very long password
                ("agent_id", "C" * 1000),  # Long agent ID
                ("agent_key", "D" * 10000),  # Long agent key
                ("pin", "1" * 1000),  # Long PIN
            ]

            for field, payload in oversized_payloads:
                try:
                    data = {
                        "username": ("admin" if field != "username" else payload),
                        "password": ("admin123" if field != "password" else payload),
                        "agent_id": "test" if field != "agent_id" else payload,
                        "agent_type": "testing",
                        "agent_key": (
                            self.valid_agent_key if field != "agent_key" else payload
                        ),
                    }

                    # Remove fields not relevant to the endpoint
                    if field in ["username", "password"]:
                        login_data = {
                            "username": data["username"],
                            "password": data["password"],
                        }
                        response = await session.post(
                            f"{self.base_url}/auth/login", json=login_data
                        )
                        if (
                            response.status_code == 500
                        ):  # Server error might indicate buffer overflow
                            self.add_vulnerability(
                                f"Buffer Overflow via {field}",
                                f"Oversized {field} caused server error",
                                "HIGH",
                                {
                                    "field": field,
                                    "payload_length": len(payload),
                                    "status": response.status,
                                },
                            )
                            validation_attacks.append(
                                {
                                    "method": f"Oversized {field}",
                                    "success": True,
                                }
                            )
                        else:
                            validation_attacks.append(
                                {
                                    "method": f"Oversized {field}",
                                    "success": False,
                                }
                            )

                    elif field in ["agent_id", "agent_key"]:
                        agent_data = {
                            "agent_id": data["agent_id"],
                            "agent_type": data["agent_type"],
                            "agent_key": data["agent_key"],
                        }
                        response = await session.post(
                            f"{self.base_url}/auth/agent/request_temp_token",
                            json=agent_data,
                        )
                        if response.status_code == 500:
                            self.add_vulnerability(
                                f"Buffer Overflow via {field}",
                                f"Oversized {field} caused server error",
                                "HIGH",
                                {
                                    "field": field,
                                    "payload_length": len(payload),
                                    "status": response.status,
                                },
                            )
                            validation_attacks.append(
                                {
                                    "method": f"Oversized {field}",
                                    "success": True,
                                }
                            )
                        else:
                            validation_attacks.append(
                                {
                                    "method": f"Oversized {field}",
                                    "success": False,
                                }
                            )

                except Exception:
                    validation_attacks.append(
                        {"method": f"Oversized {field}", "success": False}
                    )

            # Test 5.2: Special Character Injection
            special_payloads = [
                ("Null bytes", "\x00\x00\x00"),
                ("Unicode attacks", "ą́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́́"),
                ("Control characters", "\r\n\t\b\f"),
                ("Script injection", "<script>alert('xss')</script>"),
                ("Command injection", "; cat /etc/passwd; #"),
                ("Path traversal", "../../../etc/passwd"),
                ("LDAP injection", "*))(|(cn=*)"),
                (
                    "XML injection",
                    "<?xml version='1.0'?><!DOCTYPE test [<!ENTITY xxe SYSTEM 'file:///etc/passwd'>]><test>&xxe;</test>",
                ),
            ]

            for test_name, payload in special_payloads:
                try:
                    data = {
                        "username": payload,
                        "password": payload,
                        "agent_id": payload,
                        "agent_type": payload,
                        "agent_key": payload,
                    }

                    # Test login endpoint
                    login_data = {
                        "username": data["username"],
                        "password": data["password"],
                    }
                    response = await session.post(
                        f"{self.base_url}/auth/login", json=login_data
                    )
                    result = await response.text()

                    # Check for reflected payloads or errors that might indicate injection
                    if (
                        payload in result
                        or "error" in result.lower()
                        or response.status_code == 500
                    ):
                        if response.status_code == 200:  # Successful login with payload
                            self.add_vulnerability(
                                f"Authentication Bypass via {test_name}",
                                f"Special characters bypassed authentication: {test_name}",
                                "CRITICAL",
                                {
                                    "payload": payload,
                                    "response_status": response.status,
                                },
                            )
                            validation_attacks.append(
                                {
                                    "method": f"{test_name} (Auth Bypass)",
                                    "success": True,
                                }
                            )
                        elif payload in result:  # Reflected payload
                            self.add_vulnerability(
                                f"Input Reflection - {test_name}",
                                f"Input payload reflected in response: {test_name}",
                                "MEDIUM",
                                {
                                    "payload": payload,
                                    "response_preview": result[:200],
                                },
                            )
                            validation_attacks.append(
                                {
                                    "method": f"{test_name} (Reflection)",
                                    "success": True,
                                }
                            )
                    else:
                        validation_attacks.append(
                            {"method": test_name, "success": False}
                        )

                except Exception:
                    validation_attacks.append({"method": test_name, "success": False})

        self.add_test_result(
            "Input Validation Tests",
            len([a for a in validation_attacks if a["success"]]) == 0,
            "Tested input validation mechanisms",
        )
        return validation_attacks

    async def test_authorization_escalation(self) -> List[Dict]:
        """Test 6: Authorization and privilege escalation."""
        self.log("Testing Authorization Escalation...")

        escalation_attacks = []

        async with httpx.AsyncClient() as session:
            # Get agent token first
            agent_token = None
            try:
                data = {
                    "agent_id": "test_escalation",
                    "agent_type": "testing",
                    "agent_key": self.valid_agent_key,
                }
                response = await session.post(
                    f"{self.base_url}/auth/agent/request_temp_token", json=data
                )
                if response.status_code == 200:
                    result = await response.json()
                    temp_token = result["temp_token"]

                    # Complete registration to get full token
                    reg_data = {
                        "agent_id": "test_escalation",
                        "agent_type": "testing",
                        "agent_name": "Test Agent",
                        "agent_description": "Test",
                        "capabilities": ["test"],
                    }
                    headers = {"Authorization": f"Bearer {temp_token}"}
                    reg_response = await session.post(
                        f"{self.base_url}/auth/agent/complete_registration",
                        json=reg_data,
                        headers=headers,
                    )
                    if reg_response.status_code == 200:
                        reg_result = await reg_response.json()
                        agent_token = reg_result["access_token"]
            except Exception as e:
                self.log(f"Could not obtain agent token: {e}", "WARN")

            if agent_token:
                # Test 6.1: Try to access admin-only endpoints with agent token
                admin_endpoints = [
                    (
                        "/auth/tokens/mint",
                        "POST",
                        {
                            "user_id": "attacker",
                            "agent_id": "evil",
                            "scopes": ["admin"],
                        },
                    ),
                    ("/auth/tokens/list", "GET", None),
                    ("/auth/tokens/revoke", "DELETE", {"token": "any_token"}),
                ]

                for endpoint, method, data in admin_endpoints:
                    try:
                        headers = {"Authorization": f"Bearer {agent_token}"}

                        if method == "GET":
                            response = await session.get(
                                f"{self.base_url}{endpoint}", headers=headers
                            )
                            if response.status_code == 200:
                                self.add_vulnerability(
                                    f"Authorization Bypass - {endpoint}",
                                    f"Agent token accessed admin endpoint: {endpoint}",
                                    "CRITICAL",
                                    {
                                        "endpoint": endpoint,
                                        "method": method,
                                        "status": response.status,
                                    },
                                )
                                escalation_attacks.append(
                                    {
                                        "method": f"Admin Access {endpoint}",
                                        "success": True,
                                    }
                                )
                            else:
                                escalation_attacks.append(
                                    {
                                        "method": f"Admin Access {endpoint}",
                                        "success": False,
                                    }
                                )

                        elif method == "POST":
                            response = await session.post(
                                f"{self.base_url}{endpoint}",
                                json=data,
                                headers=headers,
                            )
                            if response.status_code == 200:
                                self.add_vulnerability(
                                    f"Authorization Bypass - {endpoint}",
                                    f"Agent token accessed admin endpoint: {endpoint}",
                                    "CRITICAL",
                                    {
                                        "endpoint": endpoint,
                                        "method": method,
                                        "data": data,
                                        "status": response.status,
                                    },
                                )
                                escalation_attacks.append(
                                    {
                                        "method": f"Admin Access {endpoint}",
                                        "success": True,
                                    }
                                )
                            else:
                                escalation_attacks.append(
                                    {
                                        "method": f"Admin Access {endpoint}",
                                        "success": False,
                                    }
                                )

                        elif method == "DELETE":
                            response = await session.delete(
                                f"{self.base_url}{endpoint}",
                                json=data,
                                headers=headers,
                            )
                            if response.status_code == 200:
                                self.add_vulnerability(
                                    f"Authorization Bypass - {endpoint}",
                                    f"Agent token accessed admin endpoint: {endpoint}",
                                    "CRITICAL",
                                    {
                                        "endpoint": endpoint,
                                        "method": method,
                                        "data": data,
                                        "status": response.status,
                                    },
                                )
                                escalation_attacks.append(
                                    {
                                        "method": f"Admin Access {endpoint}",
                                        "success": True,
                                    }
                                )
                            else:
                                escalation_attacks.append(
                                    {
                                        "method": f"Admin Access {endpoint}",
                                        "success": False,
                                    }
                                )

                    except Exception:
                        escalation_attacks.append(
                            {
                                "method": f"Admin Access {endpoint}",
                                "success": False,
                            }
                        )

                # Test 6.2: Try to access other agents' resources
                try:
                    # Try to access another agent's heartbeat
                    fake_agent_id = "other_agent_999"
                    headers = {"Authorization": f"Bearer {agent_token}"}
                    response = await session.post(
                        f"{self.base_url}/agents/{fake_agent_id}/heartbeat",
                        headers=headers,
                    )
                    if response.status_code == 200:
                        self.add_vulnerability(
                            "Horizontal Privilege Escalation",
                            "Agent can access other agents' resources",
                            "HIGH",
                            {
                                "accessed_agent": fake_agent_id,
                                "status": response.status,
                            },
                        )
                        escalation_attacks.append(
                            {
                                "method": "Horizontal Escalation",
                                "success": True,
                            }
                        )
                    else:
                        escalation_attacks.append(
                            {
                                "method": "Horizontal Escalation",
                                "success": False,
                            }
                        )

                except Exception:
                    escalation_attacks.append(
                        {"method": "Horizontal Escalation", "success": False}
                    )

            # Test 6.3: Try parameter pollution for role escalation
            try:
                data = [
                    {
                        "username": "admin",
                        "password": "wrong",
                        "role": "admin",
                    },
                    {
                        "username": "admin",
                        "password": "wrong",
                        "role": ["admin", "user"],
                    },
                    {
                        "username": "attacker",  # Parameter pollution - testing override
                        "password": "wrong",
                        "role": "admin",
                    },  # Parameter pollution
                ]

                for payload in data:
                    response = await session.post(
                        f"{self.base_url}/auth/login", json=payload
                    )
                    if response.status_code == 200:
                        result = await response.json()
                        self.add_vulnerability(
                            "Parameter Pollution Privilege Escalation",
                            "Role escalation through parameter manipulation",
                            "HIGH",
                            {"payload": payload, "response": result},
                        )
                        escalation_attacks.append(
                            {"method": "Parameter Pollution", "success": True}
                        )
                    else:
                        escalation_attacks.append(
                            {"method": "Parameter Pollution", "success": False}
                        )

            except Exception:
                escalation_attacks.append(
                    {"method": "Parameter Pollution", "success": False}
                )

        self.add_test_result(
            "Authorization Escalation Tests",
            len([a for a in escalation_attacks if a["success"]]) == 0,
            "Tested privilege escalation techniques",
        )
        return escalation_attacks

    async def test_timing_attacks(self) -> List[Dict]:
        """Test 7: Timing attacks on authentication."""
        self.log("Testing Timing Attacks...")

        timing_attacks = []

        async with httpx.AsyncClient() as session:
            # Test 7.1: Username enumeration via timing
            usernames_to_test = [
                "admin",
                "administrator",
                "root",
                "user",
                "test",
                "nonexistent_user_12345",
            ]
            timing_results = {}

            for username in usernames_to_test:
                times = []
                for attempt in range(5):  # Multiple attempts for accuracy
                    try:
                        data = {
                            "username": username,
                            "password": "definitely_wrong_password",
                        }
                        start_time = time.time()
                        response = await session.post(
                            f"{self.base_url}/auth/login", json=data
                        )
                        try:
                            await response.json()  # Read full response
                        except Exception:
                            await response.aread()  # Fallback to reading raw content
                        end_time = time.time()
                        times.append(end_time - start_time)

                        # Small delay to avoid rate limiting
                        await asyncio.sleep(0.1)
                    except Exception as e:
                        self.log(f"Timing test error for {username}: {e}", "WARN")
                        break

                if times:
                    avg_time = sum(times) / len(times)
                    timing_results[username] = avg_time

            # Analyze timing differences
            if len(timing_results) >= 3:
                times_list = list(timing_results.values())
                avg_time = sum(times_list) / len(times_list)
                max_time = max(times_list)
                min_time = min(times_list)

                # If there's a significant timing difference (>50% variance)
                if (max_time - min_time) / avg_time > 0.5:
                    self.add_vulnerability(
                        "Username Enumeration via Timing",
                        "Authentication response times vary significantly based on username, enabling enumeration",
                        "MEDIUM",
                        {
                            "timing_results": timing_results,
                            "variance": (max_time - min_time) / avg_time,
                        },
                    )
                    timing_attacks.append(
                        {"method": "Username Enumeration", "success": True}
                    )
                else:
                    timing_attacks.append(
                        {"method": "Username Enumeration", "success": False}
                    )

            # Test 7.2: Agent key enumeration via timing
            agent_keys_to_test = [
                self.valid_agent_key,
                "almost_valid_key_001_secure_development",
                "test_agent_key_002_secure_development",  # Valid key
                "completely_wrong_key_123456",
                "short",
                "",
            ]

            agent_timing_results = {}
            for key in agent_keys_to_test:
                times = []
                for attempt in range(3):
                    try:
                        data = {
                            "agent_id": f"timing_test_{attempt}",
                            "agent_type": "testing",
                            "agent_key": key,
                        }
                        start_time = time.time()
                        response = await session.post(
                            f"{self.base_url}/auth/agent/request_temp_token",
                            json=data,
                        )
                        try:
                            await response.json()
                        except Exception:
                            await response.aread()
                        end_time = time.time()
                        times.append(end_time - start_time)

                        await asyncio.sleep(0.1)
                    except Exception as e:
                        self.log(f"Agent key timing test error: {e}", "WARN")
                        break

                if times:
                    avg_time = sum(times) / len(times)
                    agent_timing_results[key[:20] + "..."] = avg_time

            # Analyze agent key timing differences
            if len(agent_timing_results) >= 3:
                times_list = list(agent_timing_results.values())
                avg_time = sum(times_list) / len(times_list)
                max_time = max(times_list)
                min_time = min(times_list)

                if (
                    max_time - min_time
                ) / avg_time > 0.3:  # Lower threshold for agent keys
                    self.add_vulnerability(
                        "Agent Key Enumeration via Timing",
                        "Agent key validation response times enable key enumeration",
                        "MEDIUM",
                        {
                            "timing_results": agent_timing_results,
                            "variance": (max_time - min_time) / avg_time,
                        },
                    )
                    timing_attacks.append(
                        {"method": "Agent Key Enumeration", "success": True}
                    )
                else:
                    timing_attacks.append(
                        {"method": "Agent Key Enumeration", "success": False}
                    )

        self.add_test_result(
            "Timing Attack Tests",
            len([a for a in timing_attacks if a["success"]]) == 0,
            "Tested timing-based vulnerabilities",
        )
        return timing_attacks

    async def test_advanced_attacks(self) -> List[Dict]:
        """Test 8: Advanced attack vectors."""
        self.log("Testing Advanced Attack Vectors...")

        advanced_attacks = []

        async with httpx.AsyncClient() as session:
            # Test 8.1: HTTP Header Pollution
            header_pollution_tests = [
                {"Host": ["example.com", "attacker.com"]},  # Host header injection
                {
                    "Authorization": ["Bearer token1", "Bearer token2"]
                },  # Multiple auth headers
                {
                    "Content-Type": ["application/json", "text/plain"]
                },  # Content-Type confusion
                {"X-Forwarded-Proto": ["https", "http"]},  # Protocol confusion
            ]

            for headers in header_pollution_tests:
                try:
                    # aiohttp doesn't support duplicate headers directly, so we test other vectors
                    data = {"username": "admin", "password": "test"}

                    # Test with suspicious combinations
                    test_headers = {}
                    for key, values in headers.items():
                        test_headers[key] = values[0]  # Use first value
                        if key == "Host":
                            test_headers["X-Forwarded-Host"] = values[
                                1
                            ]  # Add as different header

                    response = await session.post(
                        f"{self.base_url}/auth/login",
                        json=data,
                        headers=test_headers,
                    )
                    result = await response.text()

                    # Check for suspicious behavior
                    if response.status_code == 200 or "attacker.com" in result:
                        self.add_vulnerability(
                            "HTTP Header Pollution",
                            f"Application vulnerable to header pollution: {list(headers.keys())[0]}",
                            "MEDIUM",
                            {
                                "headers": headers,
                                "response_status": response.status,
                            },
                        )
                        advanced_attacks.append(
                            {
                                "method": f"Header Pollution ({list(headers.keys())[0]})",
                                "success": True,
                            }
                        )
                    else:
                        advanced_attacks.append(
                            {
                                "method": f"Header Pollution ({list(headers.keys())[0]})",
                                "success": False,
                            }
                        )

                except Exception:
                    advanced_attacks.append(
                        {
                            "method": f"Header Pollution ({list(headers.keys())[0]})",
                            "success": False,
                        }
                    )

            # Test 8.2: HTTP Method Override
            method_override_tests = [
                {"X-HTTP-Method-Override": "DELETE"},
                {"X-HTTP-Method": "PUT"},
                {"X-Method-Override": "PATCH"},
                {"_method": "DELETE"},
            ]

            for override_header in method_override_tests:
                try:
                    data = {"username": "admin", "password": "test"}
                    response = await session.post(
                        f"{self.base_url}/auth/login",
                        json=data,
                        headers=override_header,
                    )
                    # If the method override changes behavior significantly
                    if response.status not in [
                        400,
                        401,
                        405,
                    ]:  # Expected errors for POST login
                        result = await response.json()
                        if response.status_code == 200:
                            self.add_vulnerability(
                                "HTTP Method Override",
                                f"Method override bypass detected: {list(override_header.keys())[0]}",
                                "MEDIUM",
                                {
                                    "override_header": override_header,
                                    "status": response.status,
                                },
                            )
                            advanced_attacks.append(
                                {
                                    "method": f"Method Override ({list(override_header.keys())[0]})",
                                    "success": True,
                                }
                            )
                        else:
                            advanced_attacks.append(
                                {
                                    "method": f"Method Override ({list(override_header.keys())[0]})",
                                    "success": False,
                                }
                            )
                    else:
                        advanced_attacks.append(
                            {
                                "method": f"Method Override ({list(override_header.keys())[0]})",
                                "success": False,
                            }
                        )

                except Exception:
                    advanced_attacks.append(
                        {
                            "method": f"Method Override ({list(override_header.keys())[0]})",
                            "success": False,
                        }
                    )

            # Test 8.3: Content-Type Confusion
            content_type_tests = [
                "application/x-www-form-urlencoded",
                "text/plain",
                "application/xml",
                "multipart/form-data",
                "application/json; charset=utf-16",
                "application/json\x00",  # Null byte injection
            ]

            for content_type in content_type_tests:
                try:
                    headers = {"Content-Type": content_type}

                    if content_type == "application/x-www-form-urlencoded":
                        data = "username=admin&password=test"
                    elif content_type == "text/plain":
                        data = '{"username": "admin", "password": "test"}'
                    else:
                        data = {"username": "admin", "password": "test"}

                    response = await session.post(
                        f"{self.base_url}/auth/login",
                        data=data,
                        headers=headers,
                    )
                    if response.status_code == 200:
                        result = await response.json()
                        if "access_token" in result:
                            self.add_vulnerability(
                                "Content-Type Confusion",
                                f"Authentication bypassed via content-type: {content_type}",
                                "HIGH",
                                {
                                    "content_type": content_type,
                                    "response": result,
                                },
                            )
                            advanced_attacks.append(
                                {
                                    "method": f"Content-Type ({content_type})",
                                    "success": True,
                                }
                            )
                        else:
                            advanced_attacks.append(
                                {
                                    "method": f"Content-Type ({content_type})",
                                    "success": False,
                                }
                            )
                    else:
                        advanced_attacks.append(
                            {
                                "method": f"Content-Type ({content_type})",
                                "success": False,
                            }
                        )

                except Exception:
                    advanced_attacks.append(
                        {
                            "method": f"Content-Type ({content_type})",
                            "success": False,
                        }
                    )

        self.add_test_result(
            "Advanced Attack Tests",
            len([a for a in advanced_attacks if a["success"]]) == 0,
            "Tested advanced attack vectors",
        )
        return advanced_attacks

    async def generate_report(self) -> str:
        """Generate comprehensive security report."""
        report = []
        report.append("=" * 80)
        report.append("ARCP SECURITY PENETRATION TEST REPORT")
        report.append("=" * 80)
        report.append(f"Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"Target: {self.base_url}")
        report.append(f"Total Tests: {len(self.test_results)}")
        report.append(f"Vulnerabilities Found: {len(self.vulnerabilities)}")
        report.append("")

        # Executive Summary
        report.append("EXECUTIVE SUMMARY")
        report.append("-" * 40)

        severity_counts = {}
        for vuln in self.vulnerabilities:
            severity = vuln["severity"]
            severity_counts[severity] = severity_counts.get(severity, 0) + 1

        if self.vulnerabilities:
            report.append("VULNERABILITIES DETECTED:")
            for severity, count in sorted(
                severity_counts.items(),
                key=lambda x: ["LOW", "MEDIUM", "HIGH", "CRITICAL"].index(x[0]),
            ):
                report.append(f"   {severity}: {count}")
        else:
            report.append("NO CRITICAL VULNERABILITIES DETECTED")

        report.append("")

        # Test Results Summary
        report.append("TEST RESULTS SUMMARY")
        report.append("-" * 40)

        passed_tests = len([t for t in self.test_results if t["success"]])
        failed_tests = len(self.test_results) - passed_tests

        report.append(f"Tests Passed: {passed_tests}/{len(self.test_results)}")
        report.append(f"Tests Failed: {failed_tests}/{len(self.test_results)}")
        report.append("")

        # Detailed Vulnerabilities
        if self.vulnerabilities:
            report.append("DETAILED VULNERABILITY REPORT")
            report.append("-" * 40)

            for i, vuln in enumerate(self.vulnerabilities, 1):
                report.append(f"\n{i}. {vuln['title']} [{vuln['severity']}]")
                report.append(f"   Description: {vuln['description']}")
                report.append(f"   Timestamp: {vuln['timestamp']}")
                if vuln.get("details"):
                    report.append(
                        f"   Details: {json.dumps(vuln['details'], indent=6)}"
                    )

        # Test Details
        report.append("\nDETAILED TEST RESULTS")
        report.append("-" * 40)

        for test in self.test_results:
            status = "PASS" if test["success"] else "FAIL"
            report.append(f"{status} {test['test']}: {test['details']}")

        # Recommendations
        report.append("\nSECURITY RECOMMENDATIONS")
        report.append("-" * 40)

        recommendations = [
            "Implement comprehensive input validation and sanitization",
            "Use constant-time comparison for authentication operations",
            "Implement proper rate limiting with multiple detection methods",
            "Add comprehensive logging and monitoring for security events",
            "Regularly rotate authentication keys and secrets",
            "Implement proper session management with secure tokens",
            "Add request size limits and timeout controls",
            "Use HTTPS-only communication with proper certificate validation",
            "Implement proper error handling that doesn't leak information",
            "Regular security testing and code reviews",
        ]

        for i, rec in enumerate(recommendations, 1):
            report.append(f"{i}. {rec}")

        report.append("\n" + "=" * 80)
        report.append("End of Security Report")
        report.append("=" * 80)

        return "\n".join(report)

    async def run_all_tests(self) -> str:
        """Run all security tests and generate report."""
        self.log("Starting Comprehensive Security Testing...")

        try:
            # Run all test categories
            await self.test_authentication_bypass()
            await self.test_token_manipulation()
            await self.test_rate_limiting_bypass()
            await self.test_session_hijacking()
            await self.test_input_validation()
            await self.test_authorization_escalation()
            await self.test_timing_attacks()
            await self.test_advanced_attacks()

            # Generate and return report
            report = await self.generate_report()
            return report

        except Exception as e:
            self.log(f"Critical error during security testing: {e}", "ERROR")
            return f"Security testing failed: {e}"


async def main():
    """Main function."""
    parser = argparse.ArgumentParser(description="ARCP Security Penetration Testing")
    parser.add_argument(
        "--target",
        default="http://localhost:8001",
        help="Target ARCP server URL",
    )
    parser.add_argument("--verbose", action="store_true", help="Verbose output")
    parser.add_argument("--output", help="Output file for report")

    args = parser.parse_args()

    print("ARCP Security Penetration Testing Suite")
    print("=" * 60)
    print(f"Target: {args.target}")
    print(f"Verbose: {args.verbose}")
    print("=" * 60)

    tester = SecurityTester(args.target, args.verbose)

    try:
        report = await tester.run_all_tests()

        if args.output:
            with open(args.output, "w") as f:
                f.write(report)
            print(f"\nReport saved to: {args.output}")
        else:
            print("\n" + report)

        # Return appropriate exit code
        if tester.vulnerabilities:
            critical_vulns = [
                v for v in tester.vulnerabilities if v["severity"] == "CRITICAL"
            ]
            high_vulns = [v for v in tester.vulnerabilities if v["severity"] == "HIGH"]

            if critical_vulns:
                print(
                    f"\nCRITICAL: {len(critical_vulns)} critical vulnerabilities found!"
                )
                return 2
            elif high_vulns:
                print(
                    f"\nWARNING: {len(high_vulns)} high-severity vulnerabilities found!"
                )
                return 1
            else:
                print(
                    f"\nINFO: {len(tester.vulnerabilities)} medium/low vulnerabilities found."
                )
                return 0
        else:
            print("\nSUCCESS: No vulnerabilities detected!")
            return 0

    except KeyboardInterrupt:
        print("\nTesting interrupted by user")
        return 130
    except Exception as e:
        print(f"\nTesting failed: {e}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
